# -*- coding: utf-8 -*-
"""
Created on Wed Oct 28 10:02:24 2020

@author: 1952640
"""

from collections import Counter
import numpy as np
import tensorflow.keras as kr
import os

# å¯¹ä¸¤ä¸ªç‰ˆæœ¬çš„pyçš„å¤„ï¿?
'''
if sys.version_info[0] > 2:
    is_py3 = True
else:
    reload(sys)
    sys.setdefaultencoding("utf-8")
    is_py3 = False
'''

#ï¿?0ä¸ªä½œä¸ºå·²ç‚¹å‡»ï¿?
#ï¿?ä¸ªå€™ï¿½?å…¶ä¸­ä¸€ä¸ªæ­£æ ·æœ¬
#å–æœ€åä¸€ï¿?ä¸€ä¸ªå‡çš„ä¸ºæµ‹è¯•ï¿?

def open_file(filename,mode='r'):
    #print(os.getcwd())
    #open('../data/val.csv', mode='w').write('\n')
    return open(filename,mode,encoding='utf-8',errors='ignore')#

# è¯»å–æ–‡ä»¶æ•°æ® è¿”å› å†…å®¹+æ ‡ç­¾ åˆ—è¡¨çš„åˆ—ï¿?
def read_file(filename):
    # åˆ—è¡¨ï¼åˆ—è¡¨ï¼ä¸æ˜¯æ•°ç»„
    contents, users, newsids = [], [], []
    with open_file(filename) as f:
        print(f)
        for line in f:
           # print('?')
            #try:
            if 1:
                #print(line.strip().split(','))
                # å°†æ¯ä¸€è¡Œçš„å…ƒç´ å˜ä¸ºlistï¼Œstrip()åˆ é™¤çš„å­—ï¿?æŒ‰ç…§split()ä¸­çš„ç¬¦å·è¿›è¡Œæ¯è¡Œå…ƒç´ åˆ†å‰²ä¸ºlistçš„å…ƒï¿?
                this_line=line.strip().split(',')
                user="".join(this_line[0])
                newid=this_line[1]
                #print(newid)
                cltime=this_line[2]
                title=this_line[3]
                content=this_line[4]
                #print('ok')
                #print(user)
                #print(title)
                if user:
                    users.append(user)
                if newid:
                    newsids.append(list(newid))
                if title:#å¦‚æœä¸æ˜¯ç©ºçš„
                   # print(list(title))
                    cont=list(title)
                    cont.extend(list(content))
                    contents.append(cont)
                    #contents.append(list(content))#ï¿?list_new çœ‹ä½œä¸€ä¸ªå¯¹è±¡ï¼Œæ•´ä½“æ‰“åŒ…æ·»åŠ ï¿?list å¯¹è±¡ä¸­ï¿½?
                    #labels.append(label)
            #except:
                #pass
    return contents, users, newsids

# æ ¹æ®è®­ç»ƒé›†æ„å»ºè¯æ±‡è¡¨ï¼Œå­˜ï¿?å‚æ•°1ï¼šè®­ç»ƒé›†æ–‡ä»¶ 2ï¼šè¯æ±‡è¡¨å‚¨å­˜æ–‡ä»¶
def build_vocab(train_dir, vocab_dir, vocab_size=5000):
    # å†…å®¹ä¸æ ‡ï¿?
    data_train, _, __ = read_file(train_dir)
    all_data = []
    #print(data_train)
    for content in data_train:
        # ï¿?list_new çœ‹ä½œä¸€ä¸ªåºåˆ—ï¼Œå°†è¿™ä¸ªåºåˆ—å’Œ list åºåˆ—åˆå¹¶ï¼Œå¹¶æ”¾åœ¨å…¶åé¢ï¿½?
        #print(content)
        all_data.extend(content)
    counter = Counter(all_data)
    # å¯¹ç›¸åŒå•è¯è¿›è¡Œè®¡æ•°ï¼Œä¸ªæ•°ä¸ºvocab_size - 1
    # è¿”å›å€¼ä¸º[(xx,1),(xxx,2)]
    count_pairs = counter.most_common(vocab_size - 1)
    #print(data_train)
    #print(count_pairs)
    # *å°†å…ƒï¿?ä¸å¯æ›´æ”¹)è§£å‹ä¸ºåˆ—ï¿?
    # zipå°†å¯¹è±¡ä¸­å¯¹åº”çš„å…ƒç´ æ‰“åŒ…æˆä¸€ä¸ªä¸ªå…ƒç»„ï¼Œç„¶åè¿”å›ç”±è¿™äº›å…ƒç»„ç»„æˆçš„åˆ—è¡¨ï¿½?
    # zip() è¿”å›çš„æ˜¯ä¸€ä¸ªå¯¹è±¡ã€‚å¦‚éœ€å±•ç¤ºåˆ—è¡¨ï¼Œéœ€æ‰‹åŠ¨ list() è½¬æ¢ï¿?
    words, _ = list(zip(*count_pairs))#è¿™é‡Œæ˜¯è§£å‹ç¼© wordsæ˜¯è¯ï¿?_æ˜¯è®¡ï¿?
    # æ·»åŠ ä¸€ï¿?<PAD> æ¥å°†æ‰€æœ‰æ–‡æœ¬padä¸ºåŒä¸€é•¿åº¦
    words = ['<PAD>'] + list(words)
    # å†™å…¥è¯æ±‡è¡¨æ–‡ï¿?
    open_file(vocab_dir, mode='w').write('\n'.join(words) + '\n')

# ä»è¯æ±‡è¡¨æ–‡ä»¶è¯»å–è¯æ±‡ï¿?
def read_vocab(vocab_dir):
    with open_file(vocab_dir) as fp:
        words = [_.strip() for _ in fp.readlines()]
    #æŠŠè¯æ±‡è¡¨è½¬åŒ–ä¸ºå­—ï¿?
    word_to_id = dict(zip(words, range(len(words))))
    return words, word_to_id


def read_category():
    categories = ['ä½“è‚²', 'è´¢ç»', 'æˆ¿äº§', 'å®¶å±…', 'æ•™è‚²', 'ç§‘æŠ€', 'æ—¶å°š', 'æ—¶æ”¿', 'æ¸¸æˆ', 'å¨±ä¹']
    categories = [x for x in categories]
    cat_to_id = dict(zip(categories, range(len(categories))))
    return categories, cat_to_id

# å°†idè¡¨ç¤ºçš„å†…å®¹è½¬æ¢ä¸ºæ–‡å­—
# word[id]=è¯æ±‡
def to_words(content, words):
    return ''.join(words[x] for x in content)#ç”Ÿæˆä¸€ä¸ªå­—ç¬¦ä¸²

# å°†æ–‡ä»¶è½¬æ¢ä¸ºid å³æ–‡å­—å˜ä¸ºæ•°å­—åˆ—ï¿?
# å­—å…¸çš„è®¿ï¿?id['name']
# è¿”å›å†…å®¹
# è¯å‘é‡ä¼šåœ¨encoderé‡Œç”Ÿæˆï¼Œè¿™é‡Œä¸éœ€è¦ç”Ÿæˆè¯å‘é‡
def process_file(filename, word_to_id, cat_to_id, max_length=600):
    contents, users, newsids = read_file(filename)
    data_id = []
    for i in range(len(contents)):
        # å°†è¯¥æ¡æ–°é—»çš„æ¯ä¸ªè¯è½¬åŒ–ä¸ºid
        data_id.append([word_to_id[x] for x in contents[i] if x in word_to_id])
        #label_id.append(cat_to_id[labels[i]])# æŠŠè¯¥æ¡æ–°é—»çš„ç±»å‹è½¬ä¸ºid
    # ä½¿ç”¨kerasæä¾›çš„pad_sequencesæ¥å°†æ–‡æœ¬padä¸ºå›ºå®šé•¿ï¿?
    news = kr.preprocessing.sequence.pad_sequences(data_id, max_length)
    # å°†æ ‡ç­¾è½¬æ¢ä¸ºone-hotè¡¨ç¤º
    # y_pad = kr.utils.to_categorical(label_id, num_classes=len(cat_to_id))  
    '''
    æ–°é—»æ ‡é¢˜æ•°é‡*ç±»åˆ«
    [1,0,0,0]
    [0,1,0,0]
    ....
    '''
    return news,users #, y_pad

# ç”Ÿæˆæ‰¹æ¬¡æ•°æ®
# ä»¥ä¸€ä¸ªç”¨æˆ·ä¸ºä¸€ä¸ªè®­ç»ƒæ‰¹ï¿?
# å–å‰70%ä½œä¸ºè®­ç»ƒé›†ï¼Œå–æ­¤æ•°æ®å¼€ï¿?0æ¡ä¸ºå€™é€‰æ–°ï¿?
# è¿”å›è®­ç»ƒé›†ï¼Œå€™é€‰æ–°é—»ï¼Œç¡®å®è¢«æµè§ˆçš„æ–°é—»
def batch_iter(news,users,max_length=600,candidate_num=5,click_num=20,batch_size=64):
    user_count=Counter(users)
    i=0
    #ç¬¬ä¸€æ¡æ˜¯é¢„æµ‹çš„æ­£æ ·æœ¬
    tot_news=len(news)
    while (i<tot_news):
        batch_click,batch_candidate,batch_real=[],[],[]
        #pad=[0]*max_length
        j=0
        while(j<batch_size):
            click=int(user_count[users[i]]-2)
            if(click>click_num):
                click=click_num
            if(click<=3):
                i+=user_count[users[i]]
                continue
            input_click=news[i+1:i+click+1]
            input_real=news[i:i+1]
            #print(input_click.shape)
            if(click<click_num):
                pad=np.zeros(shape=(click_num-click,input_click.shape[-1]),dtype=np.int)
                input_click=np.concatenate((input_click,pad))
                #input_click[click_num-1][0]=-1
                #input_click[click_num-1][1]=click
                click=click_num
                #print(input_click.shape)
            #append(input_real)
            #print('--')
            #print(i+user_count[users[i]])
            #print(i+user_count[users[i]]+candidate_num-1)
            #print('--')
            if(i+user_count[users[i]]+candidate_num-1>tot_news):
                return
            input_candidate=np.concatenate((input_real,news[i+user_count[users[i]]:i+user_count[users[i]]+candidate_num-1]))
            #print(input_click.shape)
            #print(input_candidate.shape)

            if (i+click_num+candidate_num)<tot_news:
                batch_click.append(input_click)
                batch_candidate.append(input_candidate)
                batch_real.append(input_real)
                j+=1
                #yield input_click,input_candidate,input_real 
                #yield news[i:i+click_num],news[i+click_num+1:i+click_num+candidate_num],news[i+click_num+1:i+user_count[users[i]]]
            else:
                return 
            i+=user_count[users[i]]
        yield batch_click,batch_candidate,batch_real

def test_process_file(filename, word_to_id, cat_to_id, max_length=600):
    contents, users, newsids = read_file(filename)
    data_id = []
    for i in range(len(contents)):
        # å°†è¯¥æ¡æ–°é—»çš„æ¯ä¸ªè¯è½¬åŒ–ä¸ºid
        data_id.append([word_to_id[x] for x in contents[i] if x in word_to_id])
        #label_id.append(cat_to_id[labels[i]])# æŠŠè¯¥æ¡æ–°é—»çš„ç±»å‹è½¬ä¸ºid
    # ä½¿ç”¨kerasæä¾›çš„pad_sequencesæ¥å°†æ–‡æœ¬padä¸ºå›ºå®šé•¿ï¿?
    news = kr.preprocessing.sequence.pad_sequences(data_id, max_length)
    # å°†æ ‡ç­¾è½¬æ¢ä¸ºone-hotè¡¨ç¤º
    # y_pad = kr.utils.to_categorical(label_id, num_classes=len(cat_to_id))  
    '''
    æ–°é—»æ ‡é¢˜æ•°é‡*ç±»åˆ«
    [1,0,0,0]
    [0,1,0,0]
    ....
    '''
    return news,users,contents #, y_pad
            
def test_batch_iter(news,users,max_length=600,candidate_num=5,click_num=20,batch_size=64):
    user_count=Counter(users)
    i=0
    #ç¬¬ä¸€æ¡æ˜¯é¢„æµ‹çš„æ­£æ ·æœ¬
    tot_news=len(news)
    while (i<tot_news):
        batch_click,batch_candidate,batch_real,userno=[],[],[],[]
        #pad=[0]*max_length
        j=0
        while(j<batch_size):
            no=[]
            click=int(user_count[users[i]]-2)
            if(click>click_num):
                click=click_num
            if(click<=3):
                i+=user_count[users[i]]
                continue
            input_click=news[i+1:i+click+1]
            input_real=news[i:i+1]
            #print(input_click.shape)
            if(click<click_num):
                pad=np.zeros(shape=(click_num-click,input_click.shape[-1]),dtype=np.int)
                input_click=np.concatenate((input_click,pad))
                #input_click[click_num-1][0]=-1
                #input_click[click_num-1][1]=click
                click=click_num
                #print(input_click.shape)
            #append(input_real)
            #print('--')
            #print(i+user_count[users[i]])
            #print(i+user_count[users[i]]+candidate_num-1)
            #print('--')
            if(i+user_count[users[i]]+candidate_num-1>tot_news):
                return
            input_candidate=np.concatenate((input_real,news[i+user_count[users[i]]:i+user_count[users[i]]+candidate_num-1]))
            #print(input_click.shape)
            #print(input_candidate.shape)
            no.extend([i+1,i+1+click+1,i,i+user_count[users[i]],i+user_count[users[i]]+candidate_num-1])
            if (i+click_num+candidate_num)<tot_news:
                batch_click.append(input_click)
                batch_candidate.append(input_candidate)
                batch_real.append(input_real)
                userno.append(no)
                j+=1
                #yield input_click,input_candidate,input_real 
                #yield news[i:i+click_num],news[i+click_num+1:i+click_num+candidate_num],news[i+click_num+1:i+user_count[users[i]]]
            else:
                return 
            i+=user_count[users[i]]
        yield batch_click,batch_candidate,batch_real,nolist
            
